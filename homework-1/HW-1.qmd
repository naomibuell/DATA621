---
title: "Multiple Linear Regression for Baseball Win Prediction"
subtitle: "Homework #1"
format: pdf
author:
  - name: Naomi Buell
  - name: Richie Rivera
  - name: Alexander Simon
date: March 1, 2026
documentclass: article
classoption: 11pt
geometry:
  - margin=1in
header-includes:
  - \usepackage{fancyhdr}
  - \usepackage{setspace}
  - \onehalfspacing
  - \pagestyle{fancy}
  - \lhead{DATA 621}
  - \rhead{Naomi Buell, Richie Rivera, and Alexander Simon}
  - \setcounter{secnumdepth}{7}
---

```{r load-packages, include=FALSE}
# Load necessary libraries
library(tidyverse)
library(skimr)
library(corrplot)
library(ggplot2)
library(GGally)
library(janitor)
```

# Introduction

We analyze and model data on a professional baseball team from 1871 to 2006. Each record has the performance of the team for the given year, with all of the statistics adjusted to match the performance of a 162 game season. We build a multiple linear regression model on the training data to predict the number of wins for the team.

# Methods

## Data Exploration

```{r}
#| label: data-exploration
#| include: false

# Load the training and evaluation datasets
moneyball_train <- read_csv("moneyball-training-data (1).csv")
moneyball_eval <- read_csv("moneyball-evaluation-data (2).csv")

# Count rows and columns
nrows <- moneyball_train |> nrow()
ncols <- moneyball_train |> length()

# Get missingness
perc_complete <- round(moneyball_train |> n_complete() / nrows / ncols * 100, 2)
```

The mondeyball training data set contains `r nrows` rows and `r ncols` features, and is `r perc_complete` percent complete. The data are all numeric, and the target variable is `TARGET_WINS`, which represents the number of games won by the team in a season. The other variables represent various performance statistics for the team. See @tbl-summary-statistics for descriptive characteristics of the training data. Variables range from 0% to 92% missing. We address missingness by dropping columns and imputing in the Data Preparation section.

::: callout-note
NB: Not sure if target_wins represents the number of games won per season. Is each row a season? Is this the correct interpretation of the target variable?
:::

```{r}
#| label: tbl-summary-statistics
#| tbl-cap: "Summary statistics for all variables in the training dataset"
#| echo: false

tbl_summ_stats <- moneyball_train |> skim_without_charts() |> janitor::clean_names() |> as_tibble() |>
    rename(Variable = skim_variable, "Completeness rate" = complete_rate, "Mean" = numeric_mean, "SD" = numeric_sd, "P50" = numeric_p50, "Min" = numeric_p0, "P25" = numeric_p25, "P75" = numeric_p75, "Max" = numeric_p100) |>
    select(Variable, "Completeness rate", Mean, Min, P25, P50, P75, Max) |>
    mutate(across(where(is.numeric), ~ signif(., 2))) |> knitr::kable() 
tbl_summ_stats
```

```{r}
#| label: fig-correlation-matrix
#| fig-cap: "Correlation matrix of all variables in the training dataset"
#| fig.align: "center"
#| echo: false

# Get correlation matrix
moneyball_train_cor <- moneyball_train |>
    cor(use = "pairwise.complete.obs")

corrplot(moneyball_train_cor, method = "circle", type = "upper", tl.cex = 0.4, sig.level = 0.05, insig = "blank", addCoef.col = "black", number.cex = 0.3)
```

The correlation between all variables are shown @fig-correlation-matrix. The most correlated variables with the target variable `TARGET_WINS` are `TEAM_BATTING_H`, `TEAM_BATTING_2B`, and `TEAM_BATTING_BB`, which may be strong predictors of wins. The most autocorrelated variables are `TEAM_BATTING_HR` and `TEAM_PITCHING_HR`, which makes sense as teams that hit many homeruns may also allow many homeruns, for example.

::: callout-note
NB: Consider adding Bar Chart or Box Plot of the data or anything else that you think is interesting.
:::

## Data Preparation

We handled high missingness in the variables `TEAM_BATTING_HBP`, `TEAM_BASERUN_CS`, and `TEAM_FIELDING_DP` (91.6%, 33.9%, and 12.6% missing, respectively), which are not very correlated with the target variable, by excluding these variables. The remaining variables are less than 10% missing, so we will impute the missing values with the median of each variable. We avoid dropping `TEAM_BASERUN_SB` as it is the most correlated variable with the target variable that has missingness, and instead impute it to preserve this potentially strong predictor of wins.

The median imputation was picked based on the distributions of the variables with missingness: `TEAM_BASERUN_SB` and `TEAM_PITCHING_SO` have a long right tail so the median is a better imputation method than the mean. `TEAM_BATTING_SO` is bimodal, so the median is also a better imputation method than the mean for this variable. See the histograms above for the distributions of these variables. 

```{r}
#| label: histograms-missing-variables
#| fig-cap: "Histograms of variables with missingness selected for imputation"
#| warning: false
#| echo: false

# Loop through variables with missingness and create histograms
plots <- list()

# Create histogram for TEAM_BASERUN_SB
p <- ggplot(moneyball_train, aes_string(x = "TEAM_BASERUN_SB")) +
    geom_histogram() +
    theme_minimal() +
    theme(panel.grid = element_blank(), axis.text = element_text(size = 7), axis.title = element_text(size = 7)) +
    ylab("Frequency")
plots[[length(plots) + 1]] <- p

# Create histograms for other variables with missingness
vars_with_missingness <- c("TEAM_PITCHING_SO", "TEAM_BATTING_SO")
for (i in seq_along(vars_with_missingness)) {
    var <- vars_with_missingness[i]
    p <- ggplot(moneyball_train, aes_string(x = var)) +
        geom_histogram() +
        theme_minimal() +
        theme(panel.grid = element_blank(), axis.title.y = element_blank(), axis.text = element_text(size = 7), axis.title = element_text(size = 7))
    plots[[length(plots) + 1]] <- p
}

# Patch together the histograms
patchwork::wrap_plots(plots, ncol = 3) + patchwork::plot_layout(guides = 'collect')
```

*Describe how you have transformed the data by changing the original variables or creating new variables. If you did transform the data or create new variables, discuss why you did this. Here are some possible transformations.*

b.  *Create flags to suggest if a variable was missing*
c.  *Transform data by putting it into buckets*
d.  *Mathematical transforms such as log or square root (or use Box-Cox) e. Combine variables (such as ratios or adding or multiplying) to create new variables*

## Build Models

*Using the training data set, build at least three different multiple linear regression models, using different variables (or the same variables with different transformations). Since we have not yet covered automated variable selection methods, you should select the variables manually (unless you previously learned Forward or Stepwise selection, etc.). Since you manually selected a variable for inclusion into the model or exclusion into the model, indicate why this was done. Discuss the coefficients in the models, do they make sense? For example, if a team hits a lot of Home Runs, it would be reasonably expected that such a team would win more games. However, if the coefficient is negative (suggesting that the team would lose more games), then that needs to be discussed. Are you keeping the model even though it is counter intuitive? Why? The boss needs to know.*

## Select Models

*Decide on the criteria for selecting the best multiple linear regression model. Will you select a model with slightly worse performance if it makes more sense or is more parsimonious? Discuss why you selected your model. For the multiple linear regression model, will you use a metric such as Adjusted R2 , RMSE, etc.? Be sure to explain how you can make inferences from the model, discuss multi-collinearity issues (if any), and discuss other relevant model output. Using the training data set, evaluate the multiple linear regression model based on (a) mean squared error, (b) R2 , (c) F-statistic, and (d) residual plots. Make predictions using the evaluation data set.*

# Results

We predict that...

# Conclusion

In conclusion...

# Appendix: R Code

## 1. Data Exploration

First, we preview the data.

```{r}
#| label: preview-data

moneyball_train |> head()
```

The data are all numeric, and the target variable is `TARGET_WINS`, which represents the number of wins for the team in that season. The other variables represent various performance statistics for the team.

We also check summary statistics for all variables in our training data, including checking missingness.

```{r}
#| label: summary-statistics

moneyball_train |> skim()

nrows <- moneyball_train |> nrow()
ncols <- moneyball_train |> length()
perc_complete <- round(moneyball_train |> n_complete() / nrows / ncols * 100, 2)
```

This training dataset contains `r nrows` rows and `r ncols` features, and is `r perc_complete` percent complete. The variables with missingness are:

```{r}
#| label: summarize-missingness

moneyball_train |>
    summarise(across(everything(), ~ sum(is.na(.)) / nrows * 100)) |>
    pivot_longer(everything(), names_to = "variable", values_to = "missing_percentage") |>
    arrange(desc(missing_percentage)) |>
    filter(missing_percentage > 0)
```

This missingness will need to be addressed in the data preparation step.

We also visualize correlations between all variables.

```{r}
#| label: visualize-correlations

moneyball_train_cor <- moneyball_train |>
    cor(use = "pairwise.complete.obs")

corrplot(moneyball_train_cor, method = "circle", type = "upper", tl.cex = 0.7, sig.level = 0.05, insig = "blank", addCoef.col = "black", number.cex = 0.7)
```

The most correlated variables with the target variable `TARGET_WINS` are:

```{r}
#| label: most-correlated-variables

moneyball_train_cor |>
    as.data.frame() |>
    rownames_to_column(var = "variable") |>
    select(variable, TARGET_WINS) |>
    filter(variable != "TARGET_WINS") |>
    arrange(desc(abs(TARGET_WINS))) |>
    head(10)
```

These may be strong predictors of wins.

The most autocorrelated variables are:

```{r}
#| label: most-autocorrelated-variables

moneyball_train_cor |>
    as.data.frame() |>
    rownames_to_column(var = "variable1") |>
    pivot_longer(-variable1, names_to = "variable2", values_to = "correlation") |>
    filter(variable1 != variable2) |>
    distinct(across(c(correlation)), .keep_all = TRUE) |>
    arrange(desc(abs(correlation))) |>
    head(20)
```

It makes sense that homeruns by batters (`TEAM_BATTING_HR`) and homeruns allowed (`TEAM_PITCHING_HR`) are correlated, as teams that hit many homeruns may also allow many homeruns, for example. We may need to avoid including these pairs of variables in the same model to prevent multicollinearity.

We also visualize the distribution of all variables.

```{r}
#| label: visualize-distributions
#| warning: false

# Loop through all variables and create histograms
for (var in names(moneyball_train)) {
    p <- ggplot(moneyball_train, aes_string(x = var)) +
        geom_histogram() +
        labs(title = paste("Distribution of", var), x = var, y = "Frequency") +
        theme_minimal() +
        theme(panel.grid = element_blank())
    print(p)
}
```

## 2. Data Preparation

Next, we will prepare the data for modeling.

First, we handle missing data. Since we saw in the EDA that `TEAM_BATTING_HBP`, `TEAM_BASERUN_CS`, and `TEAM_FIELDING_DP` were 91.6%, 33.9%, and 12.6% missing, respectively, and not very correlated with the target variable, so we will drop these variables. The remaining variables are less than 10% missing, so we will impute the missing values with the median of each variable. `TEAM_BASERUN_SB` is the most correlated variable with the target variable that has missingness, so we will be sure to impute this variable rather than drop it.

The median imputation was picked based on the distributions of the variables with missingness: `TEAM_BASERUN_SB` and `TEAM_PITCHING_SO` have a long right tail so the median is a better imputation method than the mean. `TEAM_BATTING_SO` is bimodal, so the median is also a better imputation method than the mean for this variable. See the histograms above for the distributions of these variables.

```{r}
#| label: remove_missing_impute
moneyball_train_prepared <- moneyball_train |>
    select(-TEAM_BATTING_HBP, -TEAM_BASERUN_CS, -TEAM_FIELDING_DP) |>
    mutate(across(everything(), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))
```

## 3. Build Models

```{r}
```

## 4. Select Models

```{r}
```

Export assigned predictions (the number of wins for the team) for the evaluation data set for deliverable.

```{r}
#| label: export-predictions
```